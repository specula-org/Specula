# Specula Configuration File
# LLM Model Configuration
llm:
  base_url: "https://yunwu.ai/v1"
  # Model name - please choose a model appropriate for your API access
  model: "claude-sonnet-4-20250514"  # Options: claude-3-5-sonnet-20241022, claude-3-5-haiku-20241022
  
  # API Parameters
  max_tokens: 64000        # Maximum output tokens (claude-3-5-sonnet-20241022 has a limit of 8192)
  temperature: 0.1        # Controls randomness of generation, 0.0-1.0, lower is more deterministic
  timeout: 600           # API request timeout (seconds)
  
  # Streaming Configuration
  use_streaming: true     # Whether to use streaming
  stream_chunk_size: 2000 # Progress display interval for streaming

# TLA+ Validator Configuration
tla_validator:
  tools_path: "lib/tla2tools.jar"  # Path to TLA+ tools
  timeout: 300                      # Validator timeout (seconds)

# Generation Configuration
generation:
  max_correction_attempts: 1  # Maximum error correction attempts
  mode: "draft-based"              # Generation mode: "direct" or "draft-based"
  
# CFA Tool Configuration
cfa:
  script_path: "tools/cfa/run.sh"      # Path to CFA tool script
  input_dir: "tools/cfa/input"        # CFA input directory
  timeout: 300                         # CFA execution timeout (seconds)

# Path Configuration
paths:
  prompts_dir: "src/prompts"
  output_dir: "output"
  knowledge_base: "src/rag/initial_errors.json"
  local_embedding_model: "models/huggingface-MiniLM-L6-v2"
  
# Logging Configuration
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  format: "[%(levelname)s] %(message)s" 